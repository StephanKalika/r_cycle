---
title: "[Заметки по R](http://bdemeshev.github.io/r_cycle/): Гетероскедастичность"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: html_document
lang: russian
---

Загружаем нужные пакеты:
```{r, message=FALSE, warning=FALSE}
library("knitr") # создание отчётов
opts_chunk$set(fig.align='center') # выравнивание картинок по центру

library("ggplot2") # графики
library("sandwich") # оценка Var для гетероскедастичности
library("lmtest") # тест Бройша-Пагана
library("dplyr") # манипуляции с данными

library("Greg") # пакет Greg Макса Гордона с готовой функцией для построения доверительных интервалов при гетероскедастичности; 
# ставится с github командой devtools::install_github("gforge/Greg")

theme_set(theme_bw()) # чёрно-белая тема оформления графиков
```

Гетероскедастичность --- $Var(\epsilon_i | x_i)\neq const$.


Последствия

* Нарушены предпосылки теоремы Гаусса-Маркова. Получаемые $\hat{\beta}_{ols}$ не являются эффективными.
* Несмещенность оценок $\hat{\beta}_{ols}$ сохраняется
* Нарушены предпосылки для использования $t$-статистик. При использовании стандартных формул $t$-статистики не имеют $t$-распределения. Доверительные интервалы и проверка гипотез по стандартным формулам даёт неверные результаты.

Что делать?

* Если нужны несмещенные оценки --- ничего
* Если нужно проверять гипотезы или строить доверительные интервалы, то нужно использовать правильную формулу для $\widehat{Var}(\hat{\beta})$.
* Если нужны эффективные оценки и есть представление о том, какого вида может быть гетероскедастичность то можно взвесить наблюдения. Оценить регрессию:

\[
\frac{y_i}{\hat{\sigma}_i}=\beta_1 \frac{1}{\hat{\sigma}_i}+\beta_2 \frac{x_i}{\hat{\sigma}_i}+\frac{\epsilon_i}{\hat{\sigma}_i}
\]

* Задать другой вопрос: 
    + Вместо регрессии $y_i=\beta_1+\beta_2 x_i+\epsilon_i$ попробовать оценить регрессию $\ln(y_i)=\beta_1+\beta_2 \ln(x_i)+\epsilon_i$.
    + Оценить квантильную регрессию 

Файл с данными по стоимости квартир в Москве доступен по ссылке [goo.gl/zL5JQ](http://goo.gl/zL5JQ)

```{r, "read table"}
filename <- "../datasets/flats_moscow.txt"
h <- read.table(filename, header=TRUE)

qplot(totsp, price, data=h, 
      xlab = "Общая площадь квартиры, кв.м",
      ylab = "Цена квартиры, $1000", 
      main = "Стоимость квартир в Москве") 
```


Строим регрессию стоимости на общую площадь.
```{r}
m1 <- lm(price~totsp, data = h)
summary(m1)
```

Покажем доверительные интервалы для коэффициентов из регрессии.
```{r}
confint(m1)
```

Посмотрим на $\widehat{Var}(\hat{\beta}|X)$.
```{r}
vcov(m1)
```

Если не хотим смотреть на всё summary, а только на то, что касается бет с крышкой.
```{r}
coeftest(m1)
```

Как было сказано ранее: если в данных присутствует гетероскедастичность, но нужно проверить гипотезы и строить доверительные интервалы, то нужно использовать правильную оценку ковариационной матрицы, она выглядит так:
\[
\widehat{Var}_{HC}(\hat{\beta}|X)=(X'X)^{-1}X'\hat{\Omega}X(X'X)^{-1}
\]

\[
\hat{\Omega}=diag(\hat{\sigma}^2_1,\ldots,\hat{\sigma}^2_n)
\]

Есть разные способы состоятельно оценить отдельные дисперсии $\hat{\sigma}^2_i$, подробно можно почитать в описании пакета [`sandwich`](http://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf). Наиболее популярный на сегодня --- это так называемый "HC3":
\[
\hat{\sigma}^2_i=\frac{\hat{\epsilon}_i^2}{(1-h_{ii})^2}
\] 

Здесь $h_{ii}$ --- диагональный элемент матрицы-шляпницы (hat matrix, $\hat{y}=Hy$,  $H=X(X'X)^{-1}X'$). Матрицу-шляпницу также называют проектором, т.к. она проецирует вектор $y$ на линейную оболочку регрессоров.

Посмотрим на матрицу $\widehat{Var}_{HC}(\hat{\beta}|X)$ в R.
```{r}
vcovHC(m1)
```

Применяя правильную $\widehat{Var}_{HC}(\hat{\beta}|X)$, проверим гипотезы.
```{r}
coeftest(m1, vcov = vcovHC(m1))
```

Доверительный интервал надо строить руками. За основу мы возьмем табличку с правильными стандартными ошибками и прибавим и вычтем их от оценок коэффициентов.
```{r}
conftable <- coeftest(m1, vcov=vcovHC(m1))
ci <- data_frame(estimate = conftable[, 1], 
                 se_hc = conftable[, 2],
                 left_95 = estimate - qnorm(0.975)*se_hc,
                 right_95 = estimate + qnorm(0.975)*se_hc)
ci
```

Ещё есть малоизвестный пакет `Greg` Макса Гордона и в нём есть готовая функция:
```{r}
Greg::confint_robust(m1)
```

Пакет `Greg` не доступен на официальном репозитории CRAN, ставится с `github` командой `devtools::install_github("gforge/Greg")`.

В условиях гетероскедастичности обычная $t$-статистика не имеет ни $t$-распределения при нормальных $\varepsilon_i$, ни даже асимптотически нормального. И такая же проблема возникает с $F$-статистикой для сравнения вложенных моделей. Отныне привычная $F$-статистика 

\[
F=\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k_{UR})}
\]
не имеет ни $F$-распределения при нормальных остатках, ни $\chi^2$-распределения асимптотически. В частности, для проверки незначимости регрессии в целом некорректно использовать $F$-статистику равную $F=\frac{ESS/(k-1)}{RSS/(n-k)}$. 

Если для теста Вальда использовать корректную оценку ковариационной матрицы, то его можно применять в условиях гетероскедастичности. Допустим, мы хотим проверить гипотезу $H_0$: $A\beta=b$, состоящую из $q$ уравнений, против альтернативной о том, что хотя бы одно равенство нарушено. Тогда статистика Вальда имеет вид:

\[
W = (A\beta - b)'(A\cdot \widehat{Var}_{HC}(\hat\beta)A')^{-1}(A\beta - b)
\]
и имеет асимптотически $\chi^2$-распределение с $q$ степенями свободы.

В R реализуется с помощью опции для команды `waldtest`. Покажем на примере гипотезы о незначимости регрессии в целом:
```{r}
m0 <- lm(price~1, data = h) # оцениваем ограниченную модель (регрессия на константу)
waldtest(m0, m1, vcov=vcovHC(m1))
```


Переходим ко взвешенному МНК. Взвешенный МНК требует знания структуры гетероскедастичности, что редко встречается на практике. Предположим, что в нашем случае $Var(\epsilon_i | totsp_i) = const \cdot totsp_i$.

В R вектор весов `weights` должен быть обратно пропорционален дисперсиям, т.е. $w_i=1/\sigma^2_i$.
```{r}
model<- lm(price~totsp, weights=I(1 / totsp), data = h)
summary(model)
```


## Тесты на гетероскедастичность

Графическое обнаружение гетероскедастичности:

* Оценивается исходная регрессия и из неё получаются остатки $\hat{\varepsilon}_i$.
* Если верить в гомоскедастичность, то дисперсия вектора остатков определяется по формуле $Var(\hat{\varepsilon}|X)=\sigma^2 (I-X(X'X)^{-1}X')$. Т.е. дисперсия у остатков разная (!) даже если $Var(\varepsilon_i|X)=\sigma^2$. Поэтому остатки стандартизуют по формуле:
\[
s_i = \frac{\varepsilon_i}{\sqrt{\hat{\sigma}^2(1-h_{ii})}}
\]
Остатки полученные после такого преобразования называют стандартизированными или иногда стьюдентизированными. 
* Можно построить график зависимости величины $s_i^2$ или $|s_i|$ от переменной, предположительно повинной в гетроскедастичности.

В R:
```{r}
m1.st.resid <- rstandard(m1) # получаем стандартизированные остатки

ggplot(aes(x=totsp,y=abs(m1.st.resid)), data=h) +
  geom_point(alpha = 0.2) + 
  xlab("Общая площадь квартиры, кв.м") +
  ylab(expression(paste("Стандартизированные остатки,  ", s[i]))) +
  ggtitle("Графическое обнаружение гетероскедастичности")
```

Иногда для простоты пропускают второй шаг со стандартизацией остатков и в результате могут ошибочно принять принять разную $Var(\hat{\varepsilon}_i)$ за гетероскедастичность, т.е. за разную $Var(\varepsilon_i)$. Впрочем, если гетероскедастичность сильная, то её будет видно и на нестандартизированных остатках.


### Тест Бройша-Пагана, Breusch-Pagan:

Есть две версии теста Бройша-Пагана: авторская и современная модификация.

Предпосылки авторской версии:

* нормальность остатков, $\varepsilon_i \sim N(0,\sigma^2_i)$
* $\sigma^2_i=h(\alpha_1+\alpha_2 z_{i2}+\ldots+\alpha_{p}z_{ip})$
* у функции $h$ существуют первая и вторая производные
* тест асимптотический

Суть теста: Используя метод максимального правдоподобия посчитаем LM-статистику. При верной $H_0$ она имеет хи-квадрат распределение с $p-1$ степенью свободы.

Оказывается, что LM-статистику можно получить с помощью вспомогательной регрессии. Авторская процедура:

1. Оценивается регрессия $y_i=\beta_1+\beta_2 x_i +\varepsilon_i$
2. Переходим к $g_i=\frac{n}{SSR}\hat{\varepsilon_i}$
3. Строим регрессию $g_i$ на $\alpha_1+\alpha_2 z_{i2}+\ldots+\alpha_{p}z_{ip}$
4. $LM=\frac{ESS}{2}$


Современная модификация выглядит (неизвестный рецензент Коэнкера) так:

1. Оценивается регрессия $y_i=\beta_1+\beta_2 x_i +\varepsilon_i$
2. Оценивается регрессия $\hat{\varepsilon_i^2}$ на переменные вызывающие гетероскедастичность
3. При верной $H_0$ асимптотически:
\[
nR^2 \sim \chi^2_{p-1},
\]
где $p$ --- число оцениваемых коэффициентов во вспомогательной регрессии. По смыслу $(p-1)$ --- это количество факторов, от которых потенциально может зависеть дисперсия $Var(\varepsilon_i)$.

Тест Бройша-Пагана в R:
```{r}
bptest(m1) # версия Коэнкера
bptest(m1, studentize = FALSE) # классика Бройша-Пагана
```

У современной модификации Бройша-Пагана более слабые предпосылки:

* $H_0$: $Var(\varepsilon_i)=\sigma^2$, нормальность не требуется
* $E(\varepsilon_i^4)=const$
* тест асимптотический
* (? Коэнкер в статье критикует что-то про мощность ?)


### Тест Уайта. White test.

Предпосылки:

* $H_0$: $Var(\varepsilon_i)=\sigma^2$, нормальность не требуется
* $E(\varepsilon_i^4)=const$
* тест асимптотический

Процедура:

1. Оценивается регрессия $y_i=\beta_1+\beta_2 x_i +\varepsilon_i$
2. Строим регрессию $\hat{\varepsilon_i^2}$ на исходные регрессоры и их квадраты
3. Асимптотически $nR^2$ имеет хи-квадрат распределение

Тест Уайта в R: 
```{r}
bptest(m1, varformula = ~totsp + I(totsp^2), data = h)
```


Тест Уайта является частным случаем современной модификации теста Бройша-Пагана. В тесте Бройша-Пагана во вспомогательной регресии можно брать любые объясняющие переменные. В тесте Уайта берутся исходные регрессоры, их квадраты и попарные произведения. Если в R попросить сделать тест Бройша-Пагана и не указать спецификацию вспомогательной регрессии, то он возьмет только все регрессоры исходной.


### Тест Goldfeld-Quandt. 

Предпосылки:

* нормальность остатков, $\varepsilon_i \sim N(0,\sigma^2_i)$
* Наблюдения упорядочены по возростанию гетероскедастичности
* тест точный (неасимптотический)

Процедура:

1. Упорядочить наблюдения в том порядке, в котором подозревается рост гетероскедастичности
2. Выкинуть некий процент наблюдений по середине, чтобы подчеркнуть разницу в дисперсии между начальными и конечными наблюдениями.
3. Оценить исходную модель по наблюдениям из начала выборки и по наблюдениям конца выборки
4. Получить, соответственно, $RSS_1$ и $RSS_2$

При верной $H_0$
\[
\frac{RSS_2}{RSS_1}\sim F_{r-k,r-k},
\]
где $r$ --- размер подвыборки в начале и в конце.


Тест Голдфельда-Квандта в R:
```{r}
h2 <- h[order(h$totsp), ] # сменим порядок строк в табличке h
m2 <- lm(price~totsp, data = h2) 
gqtest(m2, fraction = 0.2) # проведем GQ тест выкинув посередине 20% наблюдений
```



### Тестирование и борьба с гетероскедастичностью

Чайники часто используют такой *ошибочный* подход:

Протестировать гетероскедастичность. Если тесты выявили гетероскедастичность, то бороться с ней (использовать устойчивые стандартные ошибки или применять взвешенный мнк). Если тесты не выявили гетероскедастичность, то не бороться с ней.

Этот подход неверен!

Правильно делать так:

* Если есть теоретические основания ожидать гетероскедастичность и наблюдений достаточно, то использовать устойчивые стандартные ошибки вне зависимости от результатов тестирования.
* Если есть теоретические основания ожидать гетероскедастичность  и наблюдений мало, то отказаться от девичьих грёз об эффективности оценок и проверке гипотез. Довольствоваться возможной несмещенностью оценок.

Тут обычно спрашивают: "А зачем же тогда тестировать на гетероскедастичность, если это решение ни на что не влияет?". Ответ прост --- чтобы узнать, есть ли гетероскедастичность. :) Впрочем, если есть теоретические основания её ожидать, то можно и не тестировать. 

### Дополнительно:

* [Описание пакета `sandwich`](http://cran.r-project.org/web/packages/sandwich/vignettes/sandwich.pdf) с очень правильным изложением современного взгляда на гетероскедастичность
* Breusch, Pagan, [Simple test for heteroskedasticity](http://www.jstor.org/stable/1911963)
* White, [A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity](http://www.jstor.org/stable/1912934)
* Koenker, [A note on studentizing a test for heteroscedasticity](http://www.sciencedirect.com/science/article/pii/0304407681900622)
* Свободный доступ к статьям на [sci-hub](http://www.sci-hub.io)


