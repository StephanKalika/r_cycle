---
title: "[Заметки по R](http://bdemeshev.github.io/r_cycle/): Апельсины и простая регрессия"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: html_document
lang: russian
---

Подгрузим необходимые пакеты:

```{r, warning=FALSE, message=FALSE}
library("tidyverse") # коллекция пакетов: ggplot2, dplyr, ...
library("lmtest") # тесты для линейных моделей
library("memisc") # сравнение моделей
library("pander") # таблички в markdown
library("broom") # стандартизация информации о модели 
library("psych") # описательные статистики
library("modelr") # добавление прогнозов/остатков
```

## Простая работа с данными до оценки регрессий

В R есть куча встроенных наборов данных. Многие пакеты в себе помимо функций содержат также ещё и примеры данных. Например, пакет `ggplot2` содержит в себе данные по стоимости бриллиантов `diamonds`.

Список всех наборов данных можно узнать с помощью команды `data()`.


Мы воспользуемся набором данных `Orange` про апельсиновые деревья.

Совсем кратко о наборе данных:
```{r}
glance(Orange)
```

Описательные статистики:
```{r}
tidy(Orange) 
```

Как выглядит начало таблички?
```{r}
head(Orange)
```

Структура набора данных. 
```{r}
str(Orange)
```

Команда `str` --- рабочая лошадка! Пакеты R пишет огромное количество людей, а она позволяет понять, из чего состоит тот или иной объект.


Более подробную информацию о наборе данных про Апельсины ищем у Чебурашки. Чебурашку можно позвать командой `help(Orange)`.

Графики
```{r}
ggplot(Orange) + 
  geom_point(aes(x = age, y = circumference, color = Tree)) + 
  labs(x = "Возраст дерева, лет", 
       y = "Диаметр ствола, мм",
  title = "Пять апельсиновых деревьев") +
  scale_colour_discrete(name = "Дерево п/п")
```


Оценим обыкновенную парную регрессию для того, чтобы понять, как диаметр дерева зависит от его возраста: 

```{r}
model <- lm(circumference ~ age, data = Orange) # оцениваем модель
report <- summary(model) # создаём отчет по модели
report # выводим отчет на экран
```

Из результатов оценивания можно вытащить

Ковариационную матрицу, $\hat{\sigma}^2(X'X)^{-1}$:
```{r}
vcov(model)
```

Любимый всеми $R^2$:
```{r}
report$r.squared
```

А также скорректированный $R^2_{adj}$:
```{r}
report$adj.r.squared
```

Коэффициенты:
```{r}
coef(model)
```

Доверительные интервалы для коэффициентов:
```{r}
confint(model, level = 0.90)
```

Отдельно табличка с результатами тестов:
```{r}
coeftest(model)
```

Несколько моделей можно сравнить рядом в одной табличке:
```{r}
model_2 <- lm(data = Orange, 
              circumference ~ age + I(age^2))
mtable(model, model_2)
```



Построим точечный прогноз диаметра дерева:
```{r}
new.data <- data_frame(age = c(100, 200, 300))
predict(model, new.data)
```

Прогноз с доверительным интервалом для среднего диаметра дерева:
```{r}
predict(model, new.data, interval = "confidence")
```


И прогноз с предиктивным интервалом для конкретного наблюдения:
```{r}
predict(model, new.data, interval = "prediction")
```

Есть удобный пакет `broom`. Основная его философия проста --- всю инфу о модели можно выдавать в `data.frame`. Пакет `broom` делит информацию на три уровня: 

* краткая о модели в целом 
* информация о коэффициентах
* то, что можно добавить к исходным данным после оценки модели. 

О модели в целом:
```{r}
glance(model)
```


Более подробную о коэффициентах:
```{r}
tidy(model)
```

Довесим исходные данные предсказанными значениями, остатками и прочим
```{r}
orange_plus <- augment(model, Orange)
glimpse(orange_plus)
```

К исходным данным добавлены:

* `.fitted` --- предсказанные $\hat y_i$
* `.se.fit` --- стандартное отклонение прогнозов $se(\hat y_i)$
* `.resid` --- остатки $\hat\varepsilon_i$
* `.hat` --- диагональный элемент матрицы-шляпницы (hat matrix), $\hat{y}=Hy$,  $H=X(X'X)^{-1}X'$, вес, с которым $y_i$ входит в формулу для $\hat y_i$.
* `.sigma` --- какой станет оценка $\hat\sigma$, если выкинуть $i$-ое наблюдение
* `.std.resid` --- стандартизованные остатки, $s_i = \frac{\hat\varepsilon_i}{\sqrt{\hat{\sigma}^2(1-h_{ii})}}$
* `.cooksd` --- расстояние Кука, $D_i$,
\[
D_i = \frac{ \sum_{j=1}^n (\hat y_j\ - \hat y_{j(-i)})^2 }{k \ \mathrm{MSE}}
\]

Однако чаще всего вместо всего этого барахла нужны лишь прогнозы:

```{r}
orange_plus_fitted <- Orange %>% add_predictions(model)
glimpse(orange_plus_fitted)
```

Или в крайнем случае остатки:

```{r}
orange_plus_residuals <- Orange %>% add_residuals(model)
glimpse(orange_plus_residuals)
```




### Расстояние Кука

> Но почему аборигены съели Кука? За что — неясно, молчит наука.
> Владимир Высоцкий

Расстояние Кука показывает, насколько сильно данное наблюдение влияет на оценённую регрессию. Насколько сильно изменятся прогнозы и оценки коэффициентов, если мы выкинем наблюдение номер $i$?
Есть у него два эквивалентных определения:
\[
D_i = \frac{ \left(\hat{\beta} - \hat{\beta}^{(-i)} \right)' X'X \left(\hat{\beta} - \hat{{\beta}}^{(-i)}\right) } {(1+k)\hat\sigma^2}
\]
И:
\[
D_i = \frac{\hat \varepsilon_i^2}{k \ \mathrm{MSE}}\left[\frac{h_{ii}}{(1-h_{ii})^2}\right]
\]
Здесь:

* $MSE$ --- среднеквадратичная ошибка, $MSE=RSS/n=\sum (y_i -\hat y_i)^2/n$
* $\hat y_j$ --- прогноз $j$-го наблюдения, построенный по всем наблюдениям
* $\hat y_{j(-i)}$ --- прогноз $j$-го наблюдения, построенный по всем наблюдениям кроме $i$-го
* $\hat \beta$ --- оценки коэффициентов, построенные по всем наблюдениям
* $\hat \beta^{(-i)}$ --- оценки коэффициентов, построенные по всем наблюдениям кроме $i$-го

С помощью расстояния Кука можно обнаруживать наблюдения сильно влияющие на результат, выбросы.
```{r}
orange_plus <- mutate(orange_plus, i = row_number())
ggplot(data = orange_plus) + 
  geom_bar(aes(x = i, 
               y = .cooksd,
               fill = age),
           stat = "identity") + 
  labs(x = "Номер наблюдения",
       y = "Расстояние Кука",
       title = "Влиятельность наблюдений")
```

На картинке мы видим, что в целом наибольшее влияние на нашу модель оказывают взрослые деревья. Два самах больших расстояния Кука --- у очень старых деревьев. Напомним, что наблюдения отсортированы по номеру дерева, а для каждого дерева --- по возрасту дерева. 


Что ещё можно вытащить из оцененной модели, можно узнать несколькими способами. Например, стоит почитать `help(summary.lm)`. Можно ещё набрать в консоли `model$` и пару раз кликнуть `<Tab>`. ещё имеет смысл попробовать нажать `<Tab>` после `summ$`. Можно набрать `str(model)`. Да ещё гугл есть.

А вообще бывает полезно изобрести велосипед. Пусть где-то в R уже есть функция, считающая доверительный интервал для прогноза. Если вместо этого написать эту функцию своими руками, то можно получить плюс один к экспириенсу и перейти на следующий уровень.


Почиташки:

* Виньетка [к пакету `broom`](https://github.com/dgrtwo/broom)
* Wiki, [Cook's distance](https://en.wikipedia.org/wiki/Cook's_distance)
* Herman Aguinis, [Best practice for handling outliers](https://www.researchgate.net/profile/Herman_Aguinis/publication/258174106_Best-Practice_Recommendations_for_Defining_Identifying_and_Handling_Outliers/links/004635276b1ff93ba8000000.pdf)
